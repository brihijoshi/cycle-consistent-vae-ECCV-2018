{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from scipy.stats import norm\n",
    "from itertools import cycle\n",
    "from random import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as opt\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "from livelossplot import PlotLosses\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "from collections import OrderedDict\n",
    "\n",
    "from cycle_consistent_vae import Encoder, Decoder\n",
    "\n",
    "np.random.bit_generator = np.random._bit_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = 1\n",
    "device = torch.device(\"cuda:{}\".format(cuda) if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "MODEL_PATH = \"./models/cycle_vae_06052020-030456_99.pth\"\n",
    "checkpoint = torch.load(MODEL_PATH)\n",
    "\n",
    "Z_DIM = 16 #Style Dimension (Unspecified)\n",
    "S_DIM = 16 # Class Dimension (Specified)\n",
    "\n",
    "encoder = Encoder(style_dim=Z_DIM, class_dim=S_DIM)\n",
    "encoder.load_state_dict(checkpoint['encoder'])\n",
    "\n",
    "decoder = Decoder(style_dim=Z_DIM, class_dim=S_DIM)\n",
    "decoder.load_state_dict(checkpoint['decoder'])\n",
    "\n",
    "\n",
    "encoder.to(device)\n",
    "encoder.eval()\n",
    "decoder.to(device)\n",
    "decoder.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reparameterize(training, mu, logvar):\n",
    "    if training:\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return eps * std + mu\n",
    "    else:\n",
    "        return mu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Latent(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.encoder = encoder\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = self.data[index][:,:,:3]\n",
    "        \n",
    "        return (img, self.labels[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# PATH = './processed/'\n",
    "# files = os.listdir(PATH)\n",
    "# data = []\n",
    "# labels = []\n",
    "\n",
    "# counter=0\n",
    "# for folder in files:\n",
    "#     print(counter)\n",
    "#     sprites = os.listdir(PATH+folder)\n",
    "#     for sprite in sprites:\n",
    "#         data.append(plt.imread(PATH+folder+\"/\"+sprite))\n",
    "#         labels.append(int(folder))\n",
    "#     counter+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(data, labels, \\\n",
    "#                                                     test_size=0.33, random_state=42, \\\n",
    "#                                                     shuffle=True, stratify=labels )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = Latent(X_train, y_train)\n",
    "# test_data = Latent(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('train_latent.pkl','wb') as f:\n",
    "#     pickle.dump(train_data, f)\n",
    "# with open('test_latent.pkl','wb') as f:\n",
    "#     pickle.dump(test_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = pickle.load(open('train_latent.pkl','rb'))\n",
    "t2 = pickle.load(open('test_latent.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "train_loader = DataLoader(t1,batch_size=BATCH_SIZE,shuffle=True,num_workers=2)\n",
    "test_loader = DataLoader(t2,batch_size=BATCH_SIZE,shuffle=True,num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES=672"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Style tranfer grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "t2",
   "language": "python",
   "name": "t2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
