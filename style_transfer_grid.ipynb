{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from scipy.stats import norm\n",
    "from itertools import cycle\n",
    "from random import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as opt\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "from livelossplot import PlotLosses\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "from collections import OrderedDict\n",
    "\n",
    "from sprites import Sprites\n",
    "from cycle_consistent_vae_in import Encoder, Decoder\n",
    "\n",
    "np.random.bit_generator = np.random._bit_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Encoder(\n",
       "  (conv_model): Sequential(\n",
       "    (conv_1): Conv2d(3, 16, kernel_size=(5, 5), stride=(2, 2), padding=(1, 1))\n",
       "    (bn_1): InstanceNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "    (relu_1): ReLU(inplace)\n",
       "    (conv_2): Conv2d(16, 32, kernel_size=(5, 5), stride=(2, 2), padding=(1, 1))\n",
       "    (bn_2): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "    (relu_2): ReLU(inplace)\n",
       "    (conv_3): Conv2d(32, 64, kernel_size=(5, 5), stride=(2, 2), padding=(1, 1))\n",
       "    (bn_3): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "    (relu_3): ReLU(inplace)\n",
       "    (conv_4): Conv2d(64, 128, kernel_size=(5, 5), stride=(2, 2), padding=(1, 1))\n",
       "    (bn_4): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "    (relu_4): ReLU(inplace)\n",
       "  )\n",
       "  (style_mu): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (style_logvar): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (class_output): Linear(in_features=512, out_features=64, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuda = 1\n",
    "device = torch.device(\"cuda:{}\".format(cuda) if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "MODEL_PATH = \"./models/cycle_vae_512_64_in_13052020-175056_499.pth\"\n",
    "checkpoint = torch.load(MODEL_PATH)\n",
    "\n",
    "Z_DIM = 512 #Style Dimension (Unspecified)\n",
    "S_DIM = 64 # Class Dimension (Specified)\n",
    "\n",
    "encoder = Encoder(style_dim=Z_DIM, class_dim=S_DIM)\n",
    "encoder.load_state_dict(checkpoint['encoder'])\n",
    "\n",
    "decoder = Decoder(style_dim=Z_DIM, class_dim=S_DIM)\n",
    "decoder.load_state_dict(checkpoint['decoder'])\n",
    "\n",
    "\n",
    "encoder.to(device)\n",
    "# encoder.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Decoder(\n",
       "  (style_input): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.2, inplace)\n",
       "  )\n",
       "  (class_input): Sequential(\n",
       "    (0): Linear(in_features=64, out_features=512, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.2, inplace)\n",
       "  )\n",
       "  (deconv_model): Sequential(\n",
       "    (deconv_1): ConvTranspose2d(256, 64, kernel_size=(4, 4), stride=(2, 2))\n",
       "    (de_bn_1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "    (leakyrelu_1): LeakyReLU(negative_slope=0.2, inplace)\n",
       "    (deconv_2): ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2))\n",
       "    (de_bn_2): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "    (leakyrelu_2): LeakyReLU(negative_slope=0.2, inplace)\n",
       "    (deconv_3): ConvTranspose2d(32, 16, kernel_size=(4, 4), stride=(2, 2))\n",
       "    (de_bn_3): InstanceNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "    (leakyrelu_3): LeakyReLU(negative_slope=0.2, inplace)\n",
       "    (deconv_4): ConvTranspose2d(16, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder.to(device)\n",
    "# decoder.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reparameterize(training, mu, logvar):\n",
    "    if training:\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return eps * std + mu\n",
    "    else:\n",
    "        return mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow_grid(images, shape=[2, 8], name='default', save=False):\n",
    "    \"\"\"\n",
    "    Plot images in a grid of a given shape.\n",
    "    Initial code from: https://github.com/pumpikano/tf-dann/blob/master/utils.py\n",
    "    \"\"\"\n",
    "    fig = plt.figure(1,figsize=(12, 12))\n",
    "    grid = ImageGrid(fig, 111, nrows_ncols=shape, axes_pad=0.05)\n",
    "\n",
    "    size = shape[0] * shape[1]\n",
    "    for i in range(size):\n",
    "        grid[i].axis('off')\n",
    "        grid[i].imshow(images[i])  # The AxesGrid object work as a list of axes.\n",
    "\n",
    "    if save:\n",
    "        plt.savefig('./figures/' + str(name) + '.png')\n",
    "        plt.clf()\n",
    "    else:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "test_data = Sprites(split='test')\n",
    "test_loader = cycle(DataLoader(test_data,batch_size=BATCH_SIZE,shuffle=True,num_workers=2, drop_last=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Style tranfer grid\n",
    "\n",
    "### Making a 9x9 grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = [None for i in range(9*9)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_constructed_sprite(class_img, style_img):\n",
    "    with torch.no_grad():\n",
    "        class_img = class_img.reshape(1,60,60,3)\n",
    "        class_img = torch.transpose(class_img, 2,3)\n",
    "        class_img = torch.transpose(class_img, 1,2)\n",
    "        \n",
    "        style_img = style_img.reshape(1,60,60,3)\n",
    "        style_img = torch.transpose(style_img, 2,3)\n",
    "        style_img = torch.transpose(style_img, 1,2)\n",
    "        \n",
    "        _, _, s_1 = encoder(class_img)\n",
    "        z_mu_1, z_logvar_1, _ = encoder(style_img)\n",
    "        z_1 = reparameterize(training=False, mu=z_mu_1, logvar=z_logvar_1)\n",
    "        \n",
    "        recons = decoder(z_1, s_1)\n",
    "        \n",
    "        return np.transpose(recons.detach().cpu().numpy(), (0, 2, 3, 1)).reshape(60,60,3)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "elem1 = next(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = elem1['img1'][:8,:,:,:].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "for i in range(9):\n",
    "    for j in range(9):\n",
    "        if i==0 and j==0:\n",
    "            count+=1\n",
    "            continue\n",
    "        elif i==0:\n",
    "            grid[count]=samples[j-1].detach().cpu().numpy()\n",
    "            count+=1\n",
    "        elif j==0:\n",
    "            grid[count]=samples[i-1].detach().cpu().numpy()\n",
    "            count+=1\n",
    "        else:\n",
    "            grid[count]=get_constructed_sprite(samples[j-1], samples[i-1])\n",
    "            count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid[0] = np.zeros(shape=(60,60,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 864x864 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imshow_grid(grid, shape=[9, 9], name='style_transfer_variety', save=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "t2",
   "language": "python",
   "name": "t2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
