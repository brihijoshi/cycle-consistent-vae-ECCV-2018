{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from scipy.stats import norm\n",
    "from itertools import cycle\n",
    "\n",
    "\n",
    "import torch\n",
    "torch.multiprocessing.set_sharing_strategy('file_system')\n",
    "from torch import nn\n",
    "import torch.optim as opt\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "from livelossplot import PlotLosses\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "from collections import OrderedDict\n",
    "\n",
    "from cycle_consistent_vae import Encoder, Decoder\n",
    "from sprites import Sprites\n",
    "\n",
    "\n",
    "np.random.bit_generator = np.random._bit_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_loss(inp, target):\n",
    "    return torch.sum((inp - target).pow(2)) / inp.data.nelement()\n",
    "\n",
    "\n",
    "def l1_loss(inp, target):\n",
    "    return torch.sum(torch.abs(inp - target)) / inp.data.nelement()\n",
    "\n",
    "def reparameterize(training, mu, logvar):\n",
    "    if training:\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return eps * std + mu\n",
    "    else:\n",
    "        return mu\n",
    "\n",
    "def weights_init(layer):\n",
    "    if isinstance(layer, nn.Conv2d):\n",
    "        layer.weight.data.normal_(0.0, 0.05)\n",
    "        layer.bias.data.zero_()\n",
    "    elif isinstance(layer, nn.BatchNorm2d):\n",
    "        layer.weight.data.normal_(1.0, 0.02)\n",
    "        layer.bias.data.zero_()\n",
    "    elif isinstance(layer, nn.Linear):\n",
    "        layer.weight.data.normal_(0.0, 0.05)\n",
    "        layer.bias.data.zero_()\n",
    "\n",
    "def kl_divergence_loss(mu, logvar):\n",
    "    loss = 3 * (- 0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp()))\n",
    "    \n",
    "    return loss / (BATCH_SIZE * 3 * 60 * 60)\n",
    "\n",
    "def imshow_grid(images, shape=[2, 8], name='default', save=False):\n",
    "    \"\"\"\n",
    "    Plot images in a grid of a given shape.\n",
    "    Initial code from: https://github.com/pumpikano/tf-dann/blob/master/utils.py\n",
    "    \"\"\"\n",
    "    fig = plt.figure(1)\n",
    "    grid = ImageGrid(fig, 111, nrows_ncols=shape, axes_pad=0.05)\n",
    "\n",
    "    size = shape[0] * shape[1]\n",
    "    for i in range(size):\n",
    "        grid[i].axis('off')\n",
    "        grid[i].imshow(images[i])  # The AxesGrid object work as a list of axes.\n",
    "\n",
    "    if save:\n",
    "        plt.savefig('./test_images2/' + str(name) + '.png')\n",
    "        plt.clf()\n",
    "    else:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = Sprites()\n",
    "test_data = Sprites(split='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = cycle(DataLoader(train_data,batch_size=BATCH_SIZE,shuffle=True,num_workers=2, drop_last=True))\n",
    "test_loader = cycle(DataLoader(test_data,batch_size=BATCH_SIZE,shuffle=True,num_workers=2, drop_last=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIME_STAMP = time.strftime(\"%d%m%Y-%H%M%S\")\n",
    "\n",
    "NUM_EPOCHS = 100\n",
    "# logging.info(\"NUM_EPOCHS - \"+ str(NUM_EPOCHS))\n",
    "\n",
    "LEARNING_RATE = 0.0001\n",
    "# logging.info(\"LEARNING_RATE - \"+ str(LEARNING_RATE))\n",
    "\n",
    "CUDA = True\n",
    "\n",
    "cuda = 1\n",
    "device = torch.device(\"cuda:{}\".format(cuda) if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "name = \"cycle_vae_test_run2\"\n",
    "liveloss = PlotLosses(fig_path='./figures/'+name+\".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_DIM = 16 #Style Dimension (Unspecified)\n",
    "S_DIM = 16 # Class Dimension (Specified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(style_dim=Z_DIM, class_dim=S_DIM)\n",
    "encoder.apply(weights_init)\n",
    "encoder.to(device)\n",
    "\n",
    "decoder = Decoder(style_dim=Z_DIM, class_dim=S_DIM)\n",
    "decoder.apply(weights_init)\n",
    "decoder.to(device)\n",
    "\n",
    "cross_entropy_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "# optimizer and scheduler definition\n",
    "auto_encoder_optimizer = opt.Adam(\n",
    "    list(encoder.parameters()) + list(decoder.parameters()),\n",
    "    lr=LEARNING_RATE,\n",
    "    betas=(0.9,0.999)\n",
    ")\n",
    "\n",
    "reverse_cycle_optimizer = opt.Adam(\n",
    "    list(encoder.parameters()),\n",
    "    lr=LEARNING_RATE,\n",
    "    betas=(0.9,0.999)\n",
    ")\n",
    "\n",
    "# divide the learning rate by a factor of 10 after 80 epochs\n",
    "auto_encoder_scheduler = opt.lr_scheduler.StepLR(auto_encoder_optimizer, step_size=80, gamma=0.1)\n",
    "reverse_cycle_scheduler = opt.lr_scheduler.StepLR(reverse_cycle_optimizer, step_size=80, gamma=0.1)\n",
    "\n",
    "normal_sampler = torch.distributions.normal.Normal(0.0, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(0,NUM_EPOCHS):\n",
    "    logs = {}\n",
    "    t_start = time.time()\n",
    "    \n",
    "    running_kl_divergence_error = 0\n",
    "    running_reconstruction_error = 0\n",
    "    running_reverse_cycle_loss = 0\n",
    "    \n",
    "    auto_encoder_scheduler.step()\n",
    "    reverse_cycle_scheduler.step()\n",
    "    \n",
    "    print('Epoch -', epoch)\n",
    "    \n",
    "    for iteration in range(int(len(train_data) / BATCH_SIZE)):\n",
    "    \n",
    "        \"\"\"\n",
    "        Training the Forward Cycle\n",
    "        \"\"\"\n",
    "#         print(\"Training forward cycle\")\n",
    "        \n",
    "        auto_encoder_optimizer.zero_grad()\n",
    "\n",
    "        elem = next(train_loader)\n",
    "        image_batch_1 = elem['img1'].to(device)\n",
    "        image_batch_1 = torch.transpose(image_batch_1, 2,3)\n",
    "        image_batch_1 = torch.transpose(image_batch_1, 1,2)\n",
    "\n",
    "        image_batch_2 = elem['img2'].to(device)\n",
    "        image_batch_2 = torch.transpose(image_batch_2, 2,3)\n",
    "        image_batch_2 = torch.transpose(image_batch_2, 1,2)\n",
    "\n",
    "\n",
    "\n",
    "        z_mu_1, z_logvar_1, s_1 = encoder(image_batch_1)\n",
    "        z_1 = reparameterize(training=True, mu=z_mu_1, logvar=z_logvar_1)\n",
    "\n",
    "        kl_divergence_loss_1 = kl_divergence_loss(z_mu_1, z_logvar_1)\n",
    "        kl_divergence_loss_1.backward(retain_graph=True)\n",
    "\n",
    "        z_mu_2, z_logvar_2, s_2 = encoder(image_batch_2)\n",
    "        z_2 = reparameterize(training=True, mu=z_mu_2, logvar=z_logvar_2)\n",
    "\n",
    "        kl_divergence_loss_2 = kl_divergence_loss(z_mu_2, z_logvar_2)\n",
    "        kl_divergence_loss_2.backward(retain_graph=True)\n",
    "\n",
    "\n",
    "        recons_1 = decoder(z_1, s_2)\n",
    "        recons_2 = decoder(z_2, s_1)\n",
    "\n",
    "\n",
    "        recons_error_1 = 2 * mse_loss(recons_1, image_batch_1)\n",
    "        recons_error_1.backward(retain_graph=True)\n",
    "\n",
    "        recons_error_2 = 2 * mse_loss(recons_2, image_batch_2)\n",
    "        recons_error_2.backward(retain_graph=True)\n",
    "\n",
    "\n",
    "        kl_divergence_error = (kl_divergence_loss_1 + kl_divergence_loss_2) / 3\n",
    "        reconstruction_error = (recons_error_1 + recons_error_2) / 2\n",
    "        \n",
    "        running_kl_divergence_error += kl_divergence_error.detach() * BATCH_SIZE\n",
    "        running_reconstruction_error += reconstruction_error.detach() * BATCH_SIZE\n",
    "\n",
    "        auto_encoder_optimizer.step()\n",
    "\n",
    "        \"\"\"\n",
    "        Training the Reverse Cycle\n",
    "        \"\"\"\n",
    "#         print(\"Training reverse cycle\")\n",
    "\n",
    "        reverse_cycle_optimizer.zero_grad()\n",
    "\n",
    "        elem1 = next(train_loader)\n",
    "        elem2 = next(train_loader)\n",
    "\n",
    "        image_batch_1 = elem1['img1'].to(device)\n",
    "        image_batch_1 = torch.transpose(image_batch_1, 2,3)\n",
    "        image_batch_1 = torch.transpose(image_batch_1, 1,2)\n",
    "\n",
    "        image_batch_2 = elem2['img1'].to(device)\n",
    "        image_batch_2 = torch.transpose(image_batch_2, 2,3)\n",
    "        image_batch_2 = torch.transpose(image_batch_2, 1,2)\n",
    "\n",
    "        z = normal_sampler.sample(sample_shape=(BATCH_SIZE,Z_DIM))\n",
    "\n",
    "        _, _, s_1 = encoder(image_batch_1)\n",
    "        _, _, s_2 = encoder(image_batch_2)\n",
    "\n",
    "        recons_1 = decoder(z.to(device), s_1.to(device))\n",
    "        recons_2 = decoder(z.to(device), s_2.to(device))\n",
    "\n",
    "        z_mu_1, z_logvar_1, _ = encoder(recons_1)\n",
    "        z_1 = reparameterize(training=False, mu=z_mu_1, logvar=z_logvar_1)\n",
    "\n",
    "        z_mu_2, z_logvar_2, _ = encoder(recons_2)\n",
    "        z_2 = reparameterize(training=False, mu=z_mu_2, logvar=z_logvar_2)\n",
    "\n",
    "        reverse_cycle_loss = 10 * l1_loss(z_1, z_2)\n",
    "        reverse_cycle_loss.backward()\n",
    "        reverse_cycle_loss /= 10\n",
    "\n",
    "        reverse_cycle_optimizer.step()\n",
    "        \n",
    "        running_reverse_cycle_loss+=reverse_cycle_loss * BATCH_SIZE\n",
    "        \n",
    "#         print(\"Training done\")\n",
    "\n",
    "\n",
    "\n",
    "    logs['kl_divergence_error'] = running_kl_divergence_error / (iteration+1)\n",
    "    logs['reconstruction_error'] = running_reconstruction_error / (iteration+1)\n",
    "    logs['reverse_cycle_loss'] = running_reverse_cycle_loss / (iteration+1)\n",
    "        \n",
    "    if (epoch) % 5 == 0 or (epoch + 1) == 100:\n",
    "        \n",
    "        torch.save({'epoch': epoch,'encoder': encoder.state_dict(),'decoder': decoder.state_dict(),\\\n",
    "                    'kl_divergence_error': logs['kl_divergence_error'], \\\n",
    "                    'reconstruction_error': logs['reconstruction_error'],\\\n",
    "                    'reverse_cycle_loss': logs['reverse_cycle_loss']}, \\\n",
    "                   \"./models/\"+name+\"_\"+TIME_STAMP+\"_\"+str(epoch)+\".pth\")\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        save reconstructed images and style swapped image generations to check progress\n",
    "        \"\"\"\n",
    "        elem1 = next(train_loader)\n",
    "        image_batch_1 = elem1['img1'].to(device)\n",
    "        image_batch_1 = torch.transpose(image_batch_1, 2,3)\n",
    "        image_batch_1 = torch.transpose(image_batch_1, 1,2)\n",
    "\n",
    "        image_batch_2 = elem1['img2'].to(device)\n",
    "        image_batch_2 = torch.transpose(image_batch_2, 2,3)\n",
    "        image_batch_2 = torch.transpose(image_batch_2, 1,2)\n",
    "        \n",
    "        \n",
    "        elem2 = next(train_loader)\n",
    "        image_batch_3 = elem2['img2'].to(device)\n",
    "        image_batch_3 = torch.transpose(image_batch_3, 2,3)\n",
    "        image_batch_3 = torch.transpose(image_batch_3, 1,2)\n",
    "  \n",
    "\n",
    "        z_mu_1, z_logvar_1, _ = encoder(image_batch_1)\n",
    "        _, __, s_2 = encoder(image_batch_2)\n",
    "        z_mu_3, z_logvar_3, _ = encoder(image_batch_3)\n",
    "\n",
    "        z_1 = reparameterize(training=False, mu=z_mu_1, logvar=z_logvar_1)\n",
    "        z_3 = reparameterize(training=False, mu=z_mu_3, logvar=z_logvar_3)\n",
    "\n",
    "        recons_1_2 = decoder(z_1, s_2)\n",
    "        recons_3_2 = decoder(z_3, s_2)\n",
    "\n",
    "        # save input image batch\n",
    "        image_batch = np.transpose(image_batch_1.detach().cpu().numpy(), (0, 2, 3, 1))\n",
    "        imshow_grid(image_batch, name=str(epoch) + '_original', save=True)\n",
    "\n",
    "        # save reconstructed batch\n",
    "        recons_x = np.transpose(recons_1_2.detach().cpu().numpy(), (0, 2, 3, 1))\n",
    "        imshow_grid(recons_x, name=str(epoch) + '_target', save=True)\n",
    "\n",
    "        style_batch = np.transpose(image_batch_3.detach().cpu().numpy(), (0, 2, 3, 1))\n",
    "        imshow_grid(style_batch, name=str(epoch) + '_style', save=True)\n",
    "\n",
    "        # save style swapped reconstructed batch\n",
    "        recons_style = np.transpose(recons_3_2.detach().cpu().numpy(), (0, 2, 3, 1))\n",
    "        imshow_grid(recons_style, name=str(epoch) + '_style_target', save=True)\n",
    "    \n",
    "    \n",
    "    delta = time.time() - t_start\n",
    "    print('Epoch time - ',delta)\n",
    "    \n",
    "\n",
    "    liveloss.update(logs)\n",
    "    liveloss.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# elem1 = next(train_loader)\n",
    "# image_batch_1 = elem1['img1'].to(device)\n",
    "# image_batch_1 = torch.transpose(image_batch_1, 2,3)\n",
    "# image_batch_1 = torch.transpose(image_batch_1, 1,2)\n",
    "\n",
    "# image_batch_2 = elem1['img2'].to(device)\n",
    "# image_batch_2 = torch.transpose(image_batch_2, 2,3)\n",
    "# image_batch_2 = torch.transpose(image_batch_2, 1,2)\n",
    "\n",
    "\n",
    "# elem2 = next(train_loader)\n",
    "# image_batch_3 = elem2['img2'].to(device)\n",
    "# image_batch_3 = torch.transpose(image_batch_3, 2,3)\n",
    "# image_batch_3 = torch.transpose(image_batch_3, 1,2)\n",
    "\n",
    "\n",
    "# z_mu_1, z_logvar_1, _ = encoder(image_batch_1)\n",
    "# _, __, s_2 = encoder(image_batch_2)\n",
    "# z_mu_3, z_logvar_3, _ = encoder(image_batch_3)\n",
    "\n",
    "# z_1 = reparameterize(training=False, mu=z_mu_1, logvar=z_logvar_1)\n",
    "# z_3 = reparameterize(training=False, mu=z_mu_3, logvar=z_logvar_3)\n",
    "\n",
    "# recons_1_2 = decoder(z_1, s_2)\n",
    "# recons_3_2 = decoder(z_3, s_2)\n",
    "\n",
    "# # save input image batch\n",
    "# image_batch = np.transpose(image_batch_1.detach().cpu().numpy(), (0, 2, 3, 1))\n",
    "# imshow_grid(image_batch, name=str(epoch) + '_original', save=False)\n",
    "\n",
    "# # save reconstructed batch\n",
    "# recons_x = np.transpose(recons_1_2.detach().cpu().numpy(), (0, 2, 3, 1))\n",
    "# imshow_grid(recons_x, name=str(epoch) + '_target', save=False)\n",
    "\n",
    "# style_batch = np.transpose(image_batch_3.detach().cpu().numpy(), (0, 2, 3, 1))\n",
    "# imshow_grid(style_batch, name=str(epoch) + '_style', save=False)\n",
    "\n",
    "# # save style swapped reconstructed batch\n",
    "# recons_style = np.transpose(recons_3_2.detach().cpu().numpy(), (0, 2, 3, 1))\n",
    "# imshow_grid(recons_style, name=str(epoch) + '_style_target', save=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL_PATH = \"./models/cycle_vae_test_run_11052020-001841_15.pth\"\n",
    "# checkpoint = torch.load(MODEL_PATH)\n",
    "\n",
    "# Z_DIM = 16 #Style Dimension (Unspecified)\n",
    "# S_DIM = 16 # Class Dimension (Specified)\n",
    "\n",
    "# encoder_test = Encoder(style_dim=Z_DIM, class_dim=S_DIM)\n",
    "# encoder_test.load_state_dict(checkpoint['encoder'])\n",
    "\n",
    "# decoder_test = Decoder(style_dim=Z_DIM, class_dim=S_DIM)\n",
    "# decoder_test.load_state_dict(checkpoint['decoder'])\n",
    "\n",
    "\n",
    "# encoder_test.to(device)\n",
    "# encoder_test.eval()\n",
    "# decoder_test.to(device)\n",
    "# decoder_test.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z_mu_1, z_logvar_1, _ = encoder_test(image_batch_1)\n",
    "# _, __, s_2 = encoder_test(image_batch_2)\n",
    "# z_mu_3, z_logvar_3, _ = encoder_test(image_batch_3)\n",
    "\n",
    "# z_1 = reparameterize(training=False, mu=z_mu_1, logvar=z_logvar_1)\n",
    "# z_3 = reparameterize(training=False, mu=z_mu_3, logvar=z_logvar_3)\n",
    "\n",
    "# recons_1_2 = decoder_test(z_1, s_2)\n",
    "# recons_3_2 = decoder_test(z_3, s_2)\n",
    "\n",
    "# # save input image batch\n",
    "# image_batch = np.transpose(image_batch_1.detach().cpu().numpy(), (0, 2, 3, 1))\n",
    "# imshow_grid(image_batch, name=str(epoch) + '_original', save=False)\n",
    "\n",
    "# # save reconstructed batch\n",
    "# recons_x = np.transpose(recons_1_2.detach().cpu().numpy(), (0, 2, 3, 1))\n",
    "# imshow_grid(recons_x, name=str(epoch) + '_target', save=False)\n",
    "\n",
    "# style_batch = np.transpose(image_batch_3.detach().cpu().numpy(), (0, 2, 3, 1))\n",
    "# imshow_grid(style_batch, name=str(epoch) + '_style', save=False)\n",
    "\n",
    "# # save style swapped reconstructed batch\n",
    "# recons_style = np.transpose(recons_3_2.detach().cpu().numpy(), (0, 2, 3, 1))\n",
    "# imshow_grid(recons_style, name=str(epoch) + '_style_target', save=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "t2",
   "language": "python",
   "name": "t2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
